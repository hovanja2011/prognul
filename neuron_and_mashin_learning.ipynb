{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input data: country, HDI for year (индекс человеческого развития), gdp_for_year (ввп в год), gdp_per_capita (ввп на душу населения).\n",
    "\n",
    "output data (m/f - пол группы, соответственно мужской и женский; два числа - это возрастная категория группы):\n",
    "\n",
    "m_5-14, m_15-24, m_25-34, m_35-54, m_55-74, m_75-, f_5-14, f_15-24, f_25-34, f_35-54, f_55-74, f_75-.\n",
    "\n",
    "method: простейшая нейронная сеть\n",
    "\n",
    "data from\n",
    "https://www.kaggle.com/russellyates88/suicide-rates-overview-1985-to-2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "import numpy as np\n",
    "from numpy import array as na\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=pd.read_csv(\"data\\suicide.csv\")\n",
    "\n",
    "\n",
    "#создаю массив входных столбцов для обучения, состав столбцов очевиден по названию, добавляю переменную gdp_for_year,\n",
    "# чтобы нормально удалить повторяющиеся данные. В конце удаляю эти значения\n",
    "X_hdi=a[\"HDI for year\"]\n",
    "X_gdp_p=a[\"gdp_per_capita ($)\"]\n",
    "X_pop=a[\" gdp_for_year ($) \"]\n",
    "\n",
    "# для создания столбцов, отвечающих за страну надо переделать слово в число так, чтобы все числа были равнозначны, для этого\n",
    "# использую OneHotEncoder, он каждой стране сопоставит вектор, причем все векторы будут равноудалены друг от друга.\n",
    "c=a[\"country\"]\n",
    "label_encoder = LabelEncoder()\n",
    "c = pd.Series(label_encoder.fit_transform(c))\n",
    "c=c.values.reshape(-1, 1)\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "matrix = onehot_encoder.fit_transform(c)\n",
    "X_c = pd.DataFrame(onehot_encoder.fit_transform(c)).T\n",
    "\n",
    "# объединяю все входные данные в единый массив\n",
    "X=np.vstack([X_c,X_hdi,X_gdp_p,X_pop]).T\n",
    "\n",
    "#удаляю повторяющиеся данные и ненужный параметр gdp_for_year\n",
    "X=pd.DataFrame(X).drop_duplicates().values\n",
    "X=X[:,:-1]\n",
    "X=X.astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дальше я строю массив ответов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=a.groupby(['country-year','sex','age'])['suicides/100k pop'].mean()\n",
    "B=pd.DataFrame(b.reset_index(name = \"count_num\"))\n",
    "table=pd.pivot_table(B, values=['count_num'], index=['sex','age'],columns=['country-year'] )\n",
    "\n",
    "Z=list()\n",
    "for i in B['country-year'].drop_duplicates():\n",
    "    Z.append(table['count_num'][i].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z.astype('float')\n",
    "1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее наконец происходит обучение, почти всё берётся из блокнота-примера.\n",
    "Я не смогла понять, какого размера должен быть скрытый слой. Поэтому решила начать с одноуровневого персептрона.\n",
    "Я так-же не разобралась с нейроном смещения, поэтому сделала так, как поняла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Функции numpy и её операции покомпонентно работают с векторами\n",
    "\n",
    "def σ(x):\n",
    "    return np.exp(-x*x) / (1 + np.exp(-x))\n",
    "\n",
    "def dσdx(x):\n",
    "    return x * (1- x+x*x)\n",
    "\n",
    "learning_throttle = 1.0\n",
    "iterations = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "#synapses\n",
    "s_1 = np.random.random((12,103))   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее происходит ошибка. Если я правильно поняла, то дело в несовпадении размеров массивов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (12,) and (103,) not aligned: 12 (dim 0) != 103 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-196-c9e1ae4efc91>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;31m# Коррекция весов\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0ms_1\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mΔ_l_2\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0ml_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m10000\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m   \u001b[1;31m# Only print the error every 10000 steps, to save time and limit the amount of output.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (12,) and (103,) not aligned: 12 (dim 0) != 103 (dim 0)"
     ]
    }
   ],
   "source": [
    "for j in range(iterations):\n",
    "    for x, z in zip(X, Z):\n",
    "    \n",
    "        # Применим нейронную сеть\n",
    "        l_1 = x\n",
    "        l_2 = σ(s_1 @ l_1)\n",
    "        \n",
    "        # Обратное распространение ошибки \n",
    "        ε_l_2 = z - l_2\n",
    "        Δ_l_2 = ε_l_2 * dσdx(l_2) * learning_throttle\n",
    "          \n",
    "        # Коррекция весов\n",
    "        s_1 += Δ_l_2 @ l_1.T\n",
    "    \n",
    "    if j % 10000 == 0:   # Only print the error every 10000 steps, to save time and limit the amount of output. \n",
    "        print(\"Error: \" + str(np.max(np.abs(ε_l_2))))\n",
    "\n",
    "    \n",
    "print(\"Output after training\")\n",
    "print(l_2)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но думаю, что есть и другая ошибка. При просмотре значений Δ_l_2, он весь заполнен Nan, чего по-моему быть не должно. И на данный момент я не знаю, как это решить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Δ_l_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
